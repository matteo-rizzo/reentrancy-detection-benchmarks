{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f0aaf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Read data from the CSV file and select only the required columns.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrs.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoolid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfindings\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# A dictionary mapping each tool to the string(s) it produces for a reentrancy finding.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# You can easily update this dictionary as needed. For tools with multiple labels,\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# use a comma-separated string, e.g., 'tool_name': 'label1,label2'.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trs.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read data from the CSV file and select only the required columns.\n",
    "df = pd.read_csv('trs.csv')\n",
    "df = df[['filename', 'toolid', 'findings']]\n",
    "\n",
    "# A dictionary mapping each tool to the string(s) it produces for a reentrancy finding.\n",
    "# You can easily update this dictionary as needed. For tools with multiple labels,\n",
    "# use a comma-separated string, e.g., 'tool_name': 'label1,label2'.\n",
    "reentrancy_labels = {\n",
    "    'ccc': 'Reentrancy_Vulnerability',\n",
    "    'confuzzius': 'Reentrancy',\n",
    "    'conkas': 'Reentrancy', #.sol 0.5\n",
    "    #'manticore-0.3.7': 'Reentrancy', # placeholder\n",
    "    'mythril-0.24.7': 'State_access_after_external_call_SWC_107',\n",
    "    'oyente+-2acaf2e': 'Re_Entrancy_Vulnerability',\n",
    "    'securify': 'DAO', \n",
    "    #'securify2': 'Reentrancy', # does not work\n",
    "    'sfuzz': 'Reentrancy', \n",
    "    'slither-0.11.3': 'reentrancy_eth,reentrancy_no_eth',\n",
    "    #'smartcheck': 'Reentrancy', # never finds any occurrence of reentrancy\n",
    "    'solhint-6.0.0': 'reentrancy',\n",
    "    #'ethainter': 'Reentrancy', # does not work\n",
    "    'ethor-2023': 'insecure',\n",
    "    'oyente+-060ca34':'Callstack_Depth_Attack_Vulnerability',\n",
    "    'vandal': 'ReentrantCall',\n",
    "    'gpt-oss': 'reentrant',\n",
    "    'gpt-5-mini': 'reentrant',\n",
    "    'gpt-5': 'reentrant',\n",
    "    'gpt-5-nano': 'reentrant'\n",
    "    }\n",
    "\n",
    "# 1. Determine the \"true\" reentrancy label for each file based on its filename.\n",
    "# 'ree' followed by an optional number indicates a true reentrancy vulnerability.\n",
    "# df['true_reentrancy'] = df['filename'].str.contains(r'ree\\d*\\.sol', case=False)\n",
    "df['true_reentrancy'] = df['filename'].str.contains(r'_ree', case=False)\n",
    "\n",
    "# 2. Determine the \"predicted\" reentrancy label based on the 'findings' column.\n",
    "# This function will check if any of the tool-specific reentrancy labels are present in the findings.\n",
    "def get_prediction(row):\n",
    "    tool_id = row['toolid']\n",
    "    findings = str(row['findings']) # Convert to string to handle potential NaN values\n",
    "    \n",
    "    # Check if the tool is in our labels dictionary.\n",
    "    if tool_id in reentrancy_labels:\n",
    "        # Split the tool's finding string into a list of individual labels.\n",
    "        tool_findings = [f.strip() for f in reentrancy_labels[tool_id].split(',')]\n",
    "        \n",
    "        # Check if any of the tool's labels are present in the findings from the data.\n",
    "        for label in tool_findings:\n",
    "            if label in findings:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df['predicted_reentrancy'] = df.apply(get_prediction, axis=1)\n",
    "\n",
    "# Save the DataFrame to a new CSV file.\n",
    "#df.to_csv('reentrancy_metrics_data.csv', index=False)\n",
    "\n",
    "# 3. Calculate metrics for each unique tool and print only the results.\n",
    "# Analyze only the tools present in the reentrancy_labels dictionary.\n",
    "tools_to_analyze = reentrancy_labels.keys()\n",
    "\n",
    "print(\"Reentrancy Metrics per Tool:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "working_tools = []\n",
    "\n",
    "for tool in tools_to_analyze:\n",
    "    \n",
    "    # Filter the DataFrame for the current tool.\n",
    "    tool_df = df[df['toolid'] == tool]\n",
    "    \n",
    "    # Calculate True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
    "    TP = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == True)])\n",
    "    FP = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == True)])\n",
    "    TN = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == False)])\n",
    "    FN = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == False)])\n",
    "    \n",
    "    # Calculate Accuracy, Precision, and Recall.\n",
    "    # Handle cases where the denominator is zero to avoid errors.\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "    \n",
    "    # Precision: Out of all positive predictions, how many were correct?\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    \n",
    "    # Recall: Out of all actual positives, how many were correctly predicted?\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # Calculate the F1 Score\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    f1_score = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n",
    "    #f1_score = f1_score(tool_df['true_reentrancy'], tool_df['predicted_reentrancy'], zero_division=0, average = 'weighted')\n",
    "    if f1_score > 0:\n",
    "        working_tools.append(tool)\n",
    "        print(f\"Tool: {tool}\")\n",
    "        print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall:    {recall:.4f}\")\n",
    "        print(f\"  F1 Score:  {f1_score:.4f}\")\n",
    "        print(\"-\" * 30)\n",
    "# Save only rows corresponding to working tools\n",
    "df_filtered = df[df['toolid'].isin(working_tools)]\n",
    "df_filtered.to_csv('reentrancy_metrics_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85095ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               filename  toolid  \\\n",
      "0     tests/bins/_safe/0x9091397ebc19163202daa16814f...  conkas   \n",
      "1     tests/bins/_safe/0xfa63eb1dc0652e7d74e6658a13a...  conkas   \n",
      "2     tests/bins/_safe/0x900ea0ba0a7cc1c8bec7792a881...  conkas   \n",
      "3     tests/bins/_safe/0x4cf56da70c06b7183cd59b7b5ed...  conkas   \n",
      "4     tests/bins/reentrant/39154ab86b53b8e3a39c30b84...  conkas   \n",
      "...                                                 ...     ...   \n",
      "8595  tests/bins/_safe/0xb02bc6401abf94d899efcc7c073...  vandal   \n",
      "8596  tests/bins/reentrant/7d6b9a034771315b63328b230...  vandal   \n",
      "8597  tests/bins/_safe/0xa52e014b3f5cc48287c2d483a3e...  vandal   \n",
      "8598  tests/bins/_safe/0x54a3017754bfba73f71f37d893a...  vandal   \n",
      "8599  tests/bins/reentrant/0x9240c2d6e42db74a5a0553b...  vandal   \n",
      "\n",
      "                           findings  \n",
      "0                                {}  \n",
      "1                                {}  \n",
      "2                                {}  \n",
      "3                                {}  \n",
      "4                                {}  \n",
      "...                             ...  \n",
      "8595                             {}  \n",
      "8596                             {}  \n",
      "8597                             {}  \n",
      "8598                             {}  \n",
      "8599  {ReentrantCall,UncheckedCall}  \n",
      "\n",
      "[8600 rows x 3 columns]\n",
      "Reentrancy Metrics per Tool:\n",
      "==============================\n",
      "Tool: ethor-2023\n",
      "  Accuracy:  0.66\n",
      "  Precision: 0.67\n",
      "  Recall:    0.02\n",
      "  F1 Score:  0.04\n",
      "------------------------------\n",
      "Tool: oyente+-060ca34\n",
      "  Accuracy:  0.73\n",
      "  Precision: 0.88\n",
      "  Recall:    0.25\n",
      "  F1 Score:  0.39\n",
      "------------------------------\n",
      "Tool: vandal\n",
      "  Accuracy:  0.74\n",
      "  Precision: 0.66\n",
      "  Recall:    0.52\n",
      "  F1 Score:  0.58\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read data from the CSV file and select only the required columns.\n",
    "df = pd.read_csv('results_aggregated_bins.csv')\n",
    "df = df[['filename', 'toolid', 'findings']]\n",
    "print(df)\n",
    "\n",
    "# Dictionary now stores a list of possible reentrancy labels per tool\n",
    "reentrancy_labels = {\n",
    "    'ccc': ['Reentrancy_Vulnerability', 'Result_of_expression_can_be_over_or_under_flown_by_external_entity'],\n",
    "    'confuzzius': ['Reentrancy'],\n",
    "    'conkas': ['Reentrancy'], \n",
    "    'mythril-0.24.7': ['State_access_after_external_call_SWC_107'],\n",
    "    'oyente+-2acaf2e': ['Re_Entrancy_Vulnerability'],\n",
    "    'securify': ['DAO'], \n",
    "    'sfuzz': ['Reentrancy'], \n",
    "    'slither-0.11.3': ['reentrancy_eth', 'reentrancy_no_eth'],\n",
    "    'solhint-6.0.0': ['reentrancy'],\n",
    "    'ethor-2023': ['insecure'],\n",
    "    'oyente+-060ca34': ['Callstack_Depth_Attack_Vulnerability'],\n",
    "    'vandal': ['ReentrantCall'],\n",
    "    'gpt-oss': ['reentrant'],\n",
    "    'gpt-5-mini': ['reentrant'],\n",
    "    'gpt-5': ['reentrant'],\n",
    "    'gpt-5-nano': ['reentrant']\n",
    "}\n",
    "\n",
    "# 1. True label from filename\n",
    "df['true_reentrancy'] = df['filename'].str.contains(r'_ree', case=False)\n",
    "\n",
    "# 2. Prediction function\n",
    "def get_prediction(row):\n",
    "    tool_id = row['toolid']\n",
    "    findings = str(row['findings'])  # convert NaN to string\n",
    "\n",
    "    if tool_id in reentrancy_labels:\n",
    "        for label in reentrancy_labels[tool_id]:\n",
    "            if label in findings:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "df['predicted_reentrancy'] = df.apply(get_prediction, axis=1)\n",
    "\n",
    "# Save updated DataFrame\n",
    "df.to_csv('reentrancy_metrics_data.csv', index=False)\n",
    "\n",
    "# 3. Metrics per tool\n",
    "tools_to_analyze = reentrancy_labels.keys()\n",
    "\n",
    "print(\"Reentrancy Metrics per Tool:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for tool in tools_to_analyze:\n",
    "    tool_df = df[df['toolid'] == tool]\n",
    "\n",
    "    TP = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == True)])\n",
    "    FP = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == True)])\n",
    "    TN = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == False)])\n",
    "    FN = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == False)])\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n",
    "\n",
    "    if f1 > 0:\n",
    "        print(f\"Tool: {tool}\")\n",
    "        print(f\"  Accuracy:  {accuracy:.2f}\")\n",
    "        print(f\"  Precision: {precision:.2f}\")\n",
    "        print(f\"  Recall:    {recall:.2f}\")\n",
    "        print(f\"  F1 Score:  {f1:.2f}\")\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reentrancy Metrics per Tool:\n",
      "==============================\n",
      "Tool: ethor-2023\n",
      "  Accuracy:  0.67\n",
      "  Precision: 0.85\n",
      "  Recall:    0.06\n",
      "  F1 Score:  0.11\n",
      "------------------------------\n",
      "Tool: oyente+-060ca34\n",
      "  Accuracy:  0.79\n",
      "  Precision: 0.93\n",
      "  Recall:    0.44\n",
      "  F1 Score:  0.59\n",
      "------------------------------\n",
      "Tool: vandal\n",
      "  Accuracy:  0.90\n",
      "  Precision: 0.78\n",
      "  Recall:    0.98\n",
      "  F1 Score:  0.87\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('results_aggregated_source.csv')\n",
    "df = df[['filename', 'toolid', 'findings']]\n",
    "\n",
    "# Dictionary of reentrancy labels per tool (lists of possible labels)\n",
    "reentrancy_labels = {\n",
    "    'ccc': ['Reentrancy_Vulnerability', 'Result_of_expression_can_be_over_or_under_flown_by_external_entity'],\n",
    "    'confuzzius': ['Reentrancy'],\n",
    "    'conkas': ['Reentrancy'], \n",
    "    'mythril-0.24.7': ['State_access_after_external_call_SWC_107'],\n",
    "    'oyente+-2acaf2e': ['Re_Entrancy_Vulnerability'],\n",
    "    'securify': ['DAO'], \n",
    "    'sfuzz': ['Reentrancy'], \n",
    "    'slither-0.11.3': ['reentrancy_eth', 'reentrancy_no_eth'],\n",
    "    'solhint-6.0.0': ['reentrancy'],\n",
    "    'ethor-2023': ['insecure'],\n",
    "    'oyente+-060ca34': ['Callstack_Depth_Attack_Vulnerability'],\n",
    "    'vandal': ['ReentrantCall'],\n",
    "    'gpt-oss': ['reentrant'],\n",
    "    'gpt-5-mini': ['reentrant'],\n",
    "    'gpt-5': ['reentrant'],\n",
    "    'gpt-5-nano': ['reentrant']\n",
    "}\n",
    "\n",
    "# 1. Prediction function\n",
    "def get_prediction(row):\n",
    "    tool_id = row['toolid']\n",
    "    findings = str(row['findings'])\n",
    "\n",
    "    if tool_id == 'ethor-2023' and findings == '':\n",
    "        return None\n",
    "    if tool_id in reentrancy_labels:\n",
    "        for label in reentrancy_labels[tool_id]:\n",
    "            if label in findings:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df['predicted_reentrancy'] = df.apply(get_prediction, axis=1)\n",
    "\n",
    "# 2. Extract folder and mark if it's reentrant or safe\n",
    "df['folder'] = df['filename'].str.extract(r'(tests/bins/[^/]+/[^/]+)')\n",
    "df['is_reentrant_folder'] = df['folder'].str.contains('reentrant', case=False, na=False)\n",
    "df['is_safe_folder'] = df['folder'].str.contains('_safe', case=False, na=False)\n",
    "\n",
    "# 3. True labels\n",
    "def true_label(row):\n",
    "    if row['is_reentrant_folder']:\n",
    "        return True   # reentrant = vulnerable\n",
    "    elif row['is_safe_folder']:\n",
    "        return False  # safe = no vulnerability\n",
    "    return False\n",
    "\n",
    "df['true_reentrancy'] = df.apply(true_label, axis=1)\n",
    "\n",
    "# 4. Folder-level aggregation:\n",
    "# for reentrant folders â†’ if any file predicted True, the whole folder counts as predicted True\n",
    "folder_predictions = (\n",
    "    df.groupby(['toolid', 'folder'])['predicted_reentrancy']\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={'predicted_reentrancy': 'folder_predicted'})\n",
    ")\n",
    "\n",
    "df = df.merge(folder_predictions, on=['toolid', 'folder'], how='left')\n",
    "\n",
    "# 5. Final prediction:\n",
    "# - use folder_predicted for reentrant folders\n",
    "# - keep file-level predicted for safe folders\n",
    "df['final_pred'] = df.apply(\n",
    "    lambda r: r['folder_predicted'] if r['is_reentrant_folder'] else r['predicted_reentrancy'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save updated DataFrame\n",
    "df.to_csv('reentrancy_metrics_data.csv', index=False)\n",
    "\n",
    "# 6. Metrics per tool\n",
    "print(\"Reentrancy Metrics per Tool:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for tool in reentrancy_labels.keys():\n",
    "    tool_df = df[df['toolid'] == tool]\n",
    "\n",
    "    TP = len(tool_df[(tool_df['true_reentrancy']) & (tool_df['final_pred'])])\n",
    "    FP = len(tool_df[(~tool_df['true_reentrancy']) & (tool_df['final_pred'])])\n",
    "    TN = len(tool_df[(~tool_df['true_reentrancy']) & (~tool_df['final_pred'])])\n",
    "    FN = len(tool_df[(tool_df['true_reentrancy']) & (~tool_df['final_pred'])])\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    if f1 > 0:\n",
    "        print(f\"Tool: {tool}\")\n",
    "        print(f\"  Accuracy:  {accuracy:.2f}\")\n",
    "        print(f\"  Precision: {precision:.2f}\")\n",
    "        print(f\"  Recall:    {recall:.2f}\")\n",
    "        print(f\"  F1 Score:  {f1:.2f}\")\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefe7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Reentrancy Analysis per Tool and Category:\n",
      "============================================================\n",
      "Tool: ccc\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: confuzzius\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: conkas\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 860)\n",
      "    TP: 0\n",
      "    FP: 2\n",
      "    TN: 559\n",
      "    FN: 299\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 860\n",
      "Tool: mythril-0.24.7\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 860)\n",
      "    TP: 0\n",
      "    FP: 0\n",
      "    TN: 563\n",
      "    FN: 297\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 860\n",
      "Tool: oyente+-2acaf2e\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: securify\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 860)\n",
      "    TP: 0\n",
      "    FP: 0\n",
      "    TN: 563\n",
      "    FN: 297\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 860\n",
      "Tool: sfuzz\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: slither-0.11.3\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: solhint-6.0.0\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: ethor-2023\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 860)\n",
      "    TP: 6\n",
      "    FP: 3\n",
      "    TN: 562\n",
      "    FN: 289\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 860\n",
      "Tool: oyente+-060ca34\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 860)\n",
      "    TP: 75\n",
      "    FP: 10\n",
      "    TN: 554\n",
      "    FN: 221\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 860\n",
      "Tool: vandal\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 860)\n",
      "    TP: 153\n",
      "    FP: 80\n",
      "    TN: 485\n",
      "    FN: 142\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 860\n",
      "Tool: gpt-oss\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: gpt-5-mini\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: gpt-5\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: gpt-5-nano\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "\n",
    "def get_file_type(filename):\n",
    "    \"\"\"\n",
    "    Extracts the file type from the path using a predefined dictionary.\n",
    "    \"\"\"\n",
    "    d = {\n",
    "        'tests/0_8/cross-contract/create/': 'create',\n",
    "        'tests/0_8/cross-contract/gmx/': 'gmx',\n",
    "        'tests/0_8/cross-contract/human/': 'human',\n",
    "        'tests/0_8/cross-contract/read-only/': 'read-only',\n",
    "        'tests/0_8/cross-contract/to-target/': 'cross-to-target',\n",
    "        'tests/0_8/always-safe/underflow/': 'underflow',\n",
    "        'tests/0_8/always-safe/emit/': 'emit',\n",
    "        'tests/0_8/always-safe/constructor/': 'safe-constructor',\n",
    "        'tests/0_8/always-safe/send-transfer/': 'send-transfer',\n",
    "        'tests/0_8/always-safe/this/': 'safe-this',\n",
    "        'tests/0_8/cross-function/guard/mutex/mod/': 'cross-function-mod',\n",
    "        'tests/0_8/cross-function/guard/mutex/no-mod/': 'cross-function-mutex',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/': 'LLC-to-sender',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard/mutex/': 'LLC-to-sender-guard-mutex',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard/access-control/': 'LLC-to-sender-guard-access-control',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard/block-number/': 'LLC-to-sender-guard-block-number',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/folded': 'LLC-to-sender-folded',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/gas': 'LLC-to-sender-gas',\n",
    "        'tests/0_8/single-function/low-level-call/to-target/': 'LLC-to-target',\n",
    "        'tests/0_8/single-function/method-invocation/': 'single-cast'\n",
    "    }\n",
    "    cat = 'unknown'\n",
    "    for prefix, category in d.items():\n",
    "        if prefix in filename:\n",
    "            cat = category\n",
    "\n",
    "    return [cat]\n",
    "\n",
    "# 3. Analyze and print TP, FP, TN, FN for each tool and category.\n",
    "print(\"Detailed Reentrancy Analysis per Tool and Category:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for tool in reentrancy_labels.keys():\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    tool_df = df[df['toolid'] == tool].copy()\n",
    "    \n",
    "    # Store metrics for each category\n",
    "    category_metrics = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    total_contracts = 0\n",
    "    for _, row in tool_df.iterrows():\n",
    "        categories = get_file_type(row['filename'])\n",
    "        true_reentrancy = row['true_reentrancy']\n",
    "        predicted_reentrancy = row['predicted_reentrancy']\n",
    "\n",
    "        for category in categories:\n",
    "            if true_reentrancy and predicted_reentrancy:\n",
    "                category_metrics[category]['TP'] += 1\n",
    "            elif not true_reentrancy and predicted_reentrancy:\n",
    "                category_metrics[category]['FP'] += 1\n",
    "            elif not true_reentrancy and not predicted_reentrancy:\n",
    "                category_metrics[category]['TN'] += 1\n",
    "            elif true_reentrancy and not predicted_reentrancy:\n",
    "                category_metrics[category]['FN'] += 1\n",
    "            \n",
    "            category_metrics[category]['total'] += 1\n",
    "\n",
    "    for category, metrics in sorted(category_metrics.items()):\n",
    "        print(f\"  Category: {category} (Total files: {metrics['total']})\")\n",
    "        print(f\"    TP: {metrics['TP']}\")\n",
    "        print(f\"    FP: {metrics['FP']}\")\n",
    "        print(f\"    TN: {metrics['TN']}\")\n",
    "        print(f\"    FN: {metrics['FN']}\")\n",
    "        print(\"-\" * 30)\n",
    "    print(\"=\" * 60)\n",
    "    total_contracts += sum(metrics['total'] for metrics in category_metrics.values())\n",
    "    print('check if I counted correctly:', total_contracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b54a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: ccc\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: confuzzius\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: conkas\n",
      "  False Positives:\n",
      "    - unknown: 2\n",
      "  False Negatives:\n",
      "    - unknown: 299\n",
      "------------------------------\n",
      "Tool: mythril-0.24.7\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    - unknown: 297\n",
      "------------------------------\n",
      "Tool: oyente+-2acaf2e\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: securify\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    - unknown: 297\n",
      "------------------------------\n",
      "Tool: sfuzz\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: slither-0.11.3\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: solhint-6.0.0\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: ethor-2023\n",
      "  False Positives:\n",
      "    - unknown: 3\n",
      "  False Negatives:\n",
      "    - unknown: 289\n",
      "------------------------------\n",
      "Tool: oyente+-060ca34\n",
      "  False Positives:\n",
      "    - unknown: 10\n",
      "  False Negatives:\n",
      "    - unknown: 221\n",
      "------------------------------\n",
      "Tool: vandal\n",
      "  False Positives:\n",
      "    - unknown: 80\n",
      "  False Negatives:\n",
      "    - unknown: 142\n",
      "------------------------------\n",
      "Tool: gpt-oss\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: gpt-5-mini\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: gpt-5\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: gpt-5-nano\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def get_file_type(filename):\n",
    "\n",
    "    d = {\n",
    "        'tests/0_8/cross-contract/create/': 'create',\n",
    "        'tests/0_8/cross-contract/gmx/': 'gmx',\n",
    "        'tests/0_8/cross-contract/human/': 'human',\n",
    "        'tests/0_8/cross-contract/read-only/': 'read-only',\n",
    "        'tests/0_8/cross-contract/to-target/': 'cross-to-target',\n",
    "        'tests/0_8/always-safe/underflow/': 'underflow',\n",
    "        'tests/0_8/always-safe/emit/': 'emit',\n",
    "        'tests/0_8/always-safe/constructor/': 'safe-constructor',\n",
    "        'tests/0_8/always-safe/send-transfer/': 'send-transfer',\n",
    "        'tests/0_8/always-safe/this/': 'safe-this',\n",
    "        'tests/0_8/cross-function/guard/mutex/mod/': 'cross-function-mod',\n",
    "        'tests/0_8/cross-function/guard/mutex/no-mod/': 'cross-function-mutex',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/': 'LLC-to-sender',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard': 'LLC-to-sender-guard',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/folded': 'LLC-to-sender-folded',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/gas': 'LLC-to-sender-gas',\n",
    "        'tests/0_8/single-function/low-level-call/to-target/': 'LLC-to-target',\n",
    "        'tests/0_8/single-function/method-invocation/': 'single-cast'\n",
    "    }\n",
    "    cat = 'unknown'\n",
    "    for prefix, category in d.items():\n",
    "        if prefix in filename:\n",
    "            cat = category\n",
    "\n",
    "    return [cat]\n",
    "\n",
    "\n",
    "for tool in tools_to_analyze:\n",
    "    tool_df = df[df['toolid'] == tool]\n",
    "\n",
    "    # Analyze False Positives (FP)\n",
    "    false_positives = tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == True)]\n",
    "    fp_categories = defaultdict(int)\n",
    "    for _, row in false_positives.iterrows():\n",
    "        categories = get_file_type(row['filename'])\n",
    "        for cat in categories:\n",
    "            fp_categories[cat] += 1\n",
    "    \n",
    "    # Analyze False Negatives (FN)\n",
    "    false_negatives = tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == False)]\n",
    "    fn_categories = defaultdict(int)\n",
    "    for _, row in false_negatives.iterrows():\n",
    "        categories = get_file_type(row['filename'])\n",
    "        for cat in categories:\n",
    "            fn_categories[cat] += 1\n",
    "\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(\"  False Positives:\")\n",
    "    if fp_categories:\n",
    "        for cat, count in sorted(fp_categories.items()):\n",
    "            print(f\"    - {cat}: {count}\")\n",
    "    else:\n",
    "        print(\"    No false positives found.\")\n",
    "    \n",
    "    print(\"  False Negatives:\")\n",
    "    if fn_categories:\n",
    "        for cat, count in sorted(fn_categories.items()):\n",
    "            print(f\"    - {cat}: {count}\")\n",
    "    else:\n",
    "        print(\"    No false negatives found.\")\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
