{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8d8b5465db6518",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 156) (2119933242.py, line 156)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"Successfully loaded '{csv_file_path}', shape: {\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 156)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "def analyze_csv_data_per_tool(df_input):\n",
    "    \"\"\"\n",
    "    Parses CSV data from a pandas DataFrame, filters data, determines ground truth\n",
    "    and predictions for Reentrancy-related findings, handles multiple runs, and\n",
    "    calculates performance metrics per toolid using sklearn.\n",
    "\n",
    "    Args:\n",
    "        df_input (pd.DataFrame): Input DataFrame from CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are toolids and values are dictionaries\n",
    "              containing calculated metrics (accuracy, precision, recall, f1_score)\n",
    "              and counts (TP, FP, TN, FN) for that tool.\n",
    "    \"\"\"\n",
    "    df = df_input.copy()  # Work on a copy\n",
    "\n",
    "    # --- Global Preprocessing on df (before splitting by tool) ---\n",
    "\n",
    "    # 2. Determine ground truth ('actual_label') and filter ambiguous filenames\n",
    "    def determine_ground_truth(filename_val):\n",
    "        if isinstance(filename_val, str):\n",
    "            filename_lower = filename_val.lower()\n",
    "            if \"ree\" in filename_lower:  # Assumes \"ree\" in filename indicates a vulnerable sample\n",
    "                return 1\n",
    "            if \"safe\" in filename_lower:  # Assumes \"safe\" in filename indicates a non-vulnerable sample\n",
    "                return 0\n",
    "        return pd.NA  # For filenames not matching 'ree' or 'safe', or if not a string\n",
    "\n",
    "    df['actual_label'] = df['filename'].apply(determine_ground_truth)\n",
    "\n",
    "    original_row_count_before_gt_filter = len(df)\n",
    "    df = df.dropna(subset=['actual_label'])  # Remove rows with pd.NA actual_label\n",
    "    print(\n",
    "        f\"Filtered out {original_row_count_before_gt_filter - len(df)} rows with ambiguous filenames (not containing 'ree' or 'safe').\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Warning: DataFrame is empty after filtering for 'ree'/'safe' filenames. No data to process.\")\n",
    "        return {}\n",
    "    df['actual_label'] = df['actual_label'].astype(int)\n",
    "\n",
    "    required_columns_for_core_logic = ['filename', 'findings', 'toolid', 'actual_label']\n",
    "    for col in required_columns_for_core_logic:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Critical Error: Column '{col}' is missing after initial processing. Cannot proceed.\")\n",
    "            return {}\n",
    "\n",
    "    results_per_tool = {}\n",
    "    if 'toolid' not in df.columns:\n",
    "        print(\"Critical Error: 'toolid' column is missing. Cannot group results.\")\n",
    "        return {}\n",
    "\n",
    "    unique_toolids = df['toolid'].unique()\n",
    "\n",
    "    for tool_id in unique_toolids:\n",
    "        tool_df_initial = df[df['toolid'] == tool_id].copy()\n",
    "\n",
    "        if tool_df_initial.empty:\n",
    "            continue\n",
    "\n",
    "        tool_df_deduplicated = pd.DataFrame()\n",
    "        if 'start' in tool_df_initial.columns:\n",
    "            tool_df_initial['start_numeric'] = pd.to_numeric(tool_df_initial['start'], errors='coerce')\n",
    "            valid_start_times_df = tool_df_initial.dropna(subset=['start_numeric'])\n",
    "\n",
    "            if not valid_start_times_df.empty:\n",
    "                tool_df_sorted = valid_start_times_df.sort_values(\n",
    "                    by=['filename', 'start_numeric'], ascending=[True, False]\n",
    "                )\n",
    "                tool_df_deduplicated = tool_df_sorted.drop_duplicates(subset=['filename'], keep='first')\n",
    "                print(\n",
    "                    f\"For toolid '{tool_id}', processed {len(tool_df_initial)} rows initially, kept {len(tool_df_deduplicated)} after deduplicating by filename (latest run with valid start time).\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: For toolid '{tool_id}', no valid numeric 'start' times. Using all {len(tool_df_initial)} rows, which might include duplicates.\")\n",
    "                tool_df_deduplicated = tool_df_initial\n",
    "        else:\n",
    "            print(\n",
    "                f\"Warning: 'start' column not found for toolid '{tool_id}'. Using all {len(tool_df_initial)} rows, which might include duplicates.\")\n",
    "            tool_df_deduplicated = tool_df_initial\n",
    "\n",
    "        if tool_df_deduplicated.empty:\n",
    "            print(f\"Warning: No data remaining for toolid '{tool_id}' after deduplication. Skipping.\")\n",
    "            results_per_tool[tool_id] = {\n",
    "                \"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0,\n",
    "                \"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0,\n",
    "                \"error\": \"No data after deduplication\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        tool_df = tool_df_deduplicated\n",
    "        y_true = tool_df['actual_label'].tolist()\n",
    "\n",
    "        # Define keywords for reentrancy-related findings (case-insensitive).\n",
    "        # This list is crucial and MUST be updated based on how YOUR tools report reentrancy.\n",
    "        reentrancy_keywords = [\n",
    "            \"reentrancy\",\n",
    "            # Broadly catches most reentrancy mentions including specific types like _eth, _no_eth, _events, _benign, _unlimited_gas\n",
    "            \"re-entrancy\",  # Variation\n",
    "            \"reentrant\",  # Adjective form\n",
    "            \"swc_107\",  # Standard Reentrancy SWC ID (will catch SWC-107 too due to .lower())\n",
    "            \"swc-107\",  # Explicitly include hyphenated version for clarity\n",
    "            \"state_access_after_external_call\",\n",
    "            # Common pattern from Mythril indicating reentrancy (often with SWC_107)\n",
    "            \"delegatecall\",\n",
    "            # Catches findings like \"Delegatecall_to_user_supplied_address...\" and \"controlled_delegatecall\"\n",
    "            \"swc_112\",  # SWC ID for Delegatecall issues, often a reentrancy vector\n",
    "            \"swc-112\",  # Hyphenated version\n",
    "            \"re_entrancy_vulnerability\",  # Oyente\n",
    "            \"dao\"  # Securify\n",
    "        ]\n",
    "        tool_df.loc[:, 'predicted_label'] = tool_df['findings'].apply(\n",
    "            lambda x: 1 if isinstance(x, str) and (\"reentrancy_benign\" not in x.lower()) and (\n",
    "                any(keyword in x.lower() for keyword in reentrancy_keywords)) else 0\n",
    "        )\n",
    "        y_pred = tool_df['predicted_label'].tolist()\n",
    "\n",
    "        if not y_true:\n",
    "            print(f\"Warning: No valid labels collected for toolid '{tool_id}'. Skipping metrics.\")\n",
    "            results_per_tool[tool_id] = {\n",
    "                \"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0,\n",
    "                \"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0,\n",
    "                \"error\": \"No valid labels after processing\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        except ValueError as e:\n",
    "            print(\n",
    "                f\"Warning: Could not compute confusion matrix directly for toolid '{tool_id}': {e}. Manually calculating.\")\n",
    "            tp = sum((yt == 1 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "            fp = sum((yt == 0 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "            tn = sum((yt == 0 and yp == 0) for yt, yp in zip(y_true, y_pred))\n",
    "            fn = sum((yt == 1 and yp == 0) for yt, yp in zip(y_true, y_pred))\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0, labels=[0, 1], pos_label=1)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0, labels=[0, 1], pos_label=1)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0, labels=[0, 1], pos_label=1)\n",
    "\n",
    "        results_per_tool[tool_id] = {\n",
    "            \"tp\": int(tp), \"fp\": int(fp), \"tn\": int(tn), \"fn\": int(fn),\n",
    "            \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1\n",
    "        }\n",
    "    return results_per_tool\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = \"trs.csv\"\n",
    "    df_main = pd.read_csv(csv_file_path)\n",
    "    print(f\"Successfully loaded '{csv_file_path}', shape: {\n",
    "        \n",
    "        \n",
    "        .shape}\")\n",
    "\n",
    "    if not df_main.empty:\n",
    "        print(\"\\nAnalyzing CSV data for Reentrancy-related findings per tool (using pandas & sklearn):\\n\")\n",
    "        all_results = analyze_csv_data_per_tool(df_main)\n",
    "\n",
    "        if not all_results:\n",
    "            print(\"No results were generated. Please check the input data and logs.\")\n",
    "        else:\n",
    "            for tool_id, metrics in all_results.items():\n",
    "                print(f\"\\nResults for toolid: {tool_id}\")\n",
    "                if \"error\" in metrics:\n",
    "                    print(f\"  Message: {metrics['error']}\")\n",
    "                elif all(k in metrics for k in [\"tp\", \"fp\", \"tn\", \"fn\"]):  # Check if full metrics dict\n",
    "                    print(f\"  True Positives (TP):  {metrics['tp']}\")\n",
    "                    print(f\"  False Positives (FP): {metrics['fp']}\")\n",
    "                    print(f\"  True Negatives (TN):  {metrics['tn']}\")\n",
    "                    print(f\"  False Negatives (FN): {metrics['fn']}\")\n",
    "                    print(\"  ------------------------------------\")\n",
    "                    print(f\"  Accuracy:             {metrics['accuracy']:.4f}\")\n",
    "                    print(f\"  Precision:            {metrics['precision']:.4f}\")\n",
    "                    print(f\"  Recall (Sensitivity): {metrics['recall']:.4f}\")\n",
    "                    print(f\"  F1-Score:             {metrics['f1_score']:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  Metrics data incomplete: {metrics}\")\n",
    "                print(\"-\" * 40)\n",
    "    else:\n",
    "        print(\n",
    "            \"Could not proceed with analysis as DataFrame is empty (either file not found/error or dummy data creation failed).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39452166ae87d909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'trs.csv', shape: (2100, 13)\n",
      "\n",
      "Analyzing CSV data for Reentrancy-related findings per tool (using pandas & sklearn):\n",
      "\n",
      "Filtered out 0 rows with ambiguous filenames (not containing 'ree' or 'safe').\n",
      "For toolid 'mythril-0.24.7', processed 150 rows initially, kept 150 after deduplicating by filename (latest run with valid start time).\n",
      "\n",
      "Misclassified contracts for toolid 'mythril-0.24.7':\n",
      "  False Positives (predicted vulnerable, actually safe):\n",
      "    - tests/handcrafted-raw/00_BasicCall_safe1.sol\n",
      "    - tests/handcrafted-raw/00_BasicEmit_safe1.sol\n",
      "    - tests/handcrafted-raw/00_BasicFold_safe1.sol\n",
      "    - tests/handcrafted-raw/00_BasicFold_safe2.sol\n",
      "    - tests/handcrafted-raw/00_BasicNoChecks_safe1.sol\n",
      "    - tests/handcrafted-raw/00_BasicUnchecked_safe1.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutexFoldSem_safe1.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutex_safe1.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutex_safe2.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutexSem_safe1.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutexUnchecked_safe1.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutex_safe1.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutex_safe2.sol\n",
      "    - tests/handcrafted-raw/03_SingleModFoldSem_safe1.sol\n",
      "    - tests/handcrafted-raw/03_SingleModSem_safe1.sol\n",
      "    - tests/handcrafted-raw/03_SingleMod_safe2.sol\n",
      "    - tests/handcrafted-raw/04_CrossModFoldSem_safe1.sol\n",
      "    - tests/handcrafted-raw/04_CrossModFold_safe1.sol\n",
      "    - tests/handcrafted-raw/04_CrossMod_safe1.sol\n",
      "    - tests/handcrafted-raw/04_CrossMod_safe2.sol\n",
      "    - tests/handcrafted-raw/07_MixedTransferEmit_safe1.sol\n",
      "    - tests/handcrafted-raw/07_MixedTransfer_safe1.sol\n",
      "    - tests/handcrafted-raw/08_MixedSendFoldEmit_safe1.sol\n",
      "    - tests/handcrafted-raw/08_MixedSendFold_safe1.sol\n",
      "    - tests/handcrafted-raw/08_MixedSend_safe1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDMod_safe1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DD_safe1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20_safe3.sol\n",
      "    - tests/handcrafted-raw/10_OnlyOnce_safe1.sol\n",
      "    - tests/handcrafted-raw/10_OnlyOnce_safe2.sol\n",
      "    - tests/handcrafted-raw/11_ERC20StakingPullMod_safe1.sol\n",
      "    - tests/handcrafted-raw/11_ERC20StakingPull_safe1.sol\n",
      "    - tests/handcrafted-raw/11_ERC20StakingPull_safe2.sol\n",
      "    - tests/handcrafted-raw/11_ERC20Staking_safe3.sol\n",
      "    - tests/handcrafted-raw/12_Proxy_safe1.sol\n",
      "    - tests/handcrafted-raw/12_Proxy_safe2.sol\n",
      "    - tests/handcrafted-raw/13_OnlyOwner_safe1.sol\n",
      "    - tests/handcrafted-raw/14_SidefxInline_safe1.sol\n",
      "    - tests/handcrafted-raw/15_LoopCrossMod_safe1.sol\n",
      "    - tests/handcrafted-raw/15_LoopCrossMutex_safe1.sol\n",
      "    - tests/handcrafted-raw/15_LoopCrossMutex_safe2.sol\n",
      "    - tests/handcrafted-raw/15_Loop_safe1.sol\n",
      "    - tests/handcrafted-raw/16_DelegateCall_safe1.sol\n",
      "    - tests/handcrafted-raw/19_HumanFold_safe1.sol\n",
      "    - tests/handcrafted-raw/19_Human_safe1.sol\n",
      "    - tests/handcrafted-raw/19_Human_safe2.sol\n",
      "    - tests/handcrafted-raw/19_Human_safe3.sol\n",
      "  False Negatives (predicted safe, actually vulnerable):\n",
      "    - tests/handcrafted-raw/00_BasicError_ree1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDSubMod_ree1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDSubMod_ree2.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDSubMod_ree3.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDSub_ree1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20OnlyOnce_ree1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20Staticcall_ree1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20_ree1.sol\n",
      "    - tests/handcrafted-raw/17_Rari_ree1.sol\n",
      "    - tests/handcrafted-raw/17_Rari_ree2.sol\n",
      "    - tests/handcrafted-raw/18_RariStaticcall_ree1.sol\n",
      "    - tests/handcrafted-raw/19_HumanFold_ree3.sol\n",
      "\n",
      "Correctly classified contracts for toolid 'mythril-0.24.7':\n",
      "  True Positives (predicted vulnerable, actually vulnerable):\n",
      "    - tests/handcrafted-raw/00_BasicCall_ree1.sol\n",
      "    - tests/handcrafted-raw/00_BasicConst_ree1.sol\n",
      "    - tests/handcrafted-raw/00_BasicCross_ree1.sol\n",
      "    - tests/handcrafted-raw/00_BasicEmit_ree1.sol\n",
      "    - tests/handcrafted-raw/00_BasicFold_ree1.sol\n",
      "    - tests/handcrafted-raw/00_BasicFold_ree2.sol\n",
      "    - tests/handcrafted-raw/00_BasicNoChecks_ree1.sol\n",
      "    - tests/handcrafted-raw/00_BasicUnchecked_ree1.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutexFoldSem_ree1.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutexFold_ree1.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutexFold_ree2.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutexFold_ree3.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutex_ree1.sol\n",
      "    - tests/handcrafted-raw/01_SingleMutex_ree2.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutexSem_ree1.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutexUnchecked_ree1.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutex_ree1.sol\n",
      "    - tests/handcrafted-raw/02_CrossMutex_ree2.sol\n",
      "    - tests/handcrafted-raw/03_SingleModFoldSem_ree1.sol\n",
      "    - tests/handcrafted-raw/03_SingleModFold_ree1.sol\n",
      "    - tests/handcrafted-raw/03_SingleModFold_ree2.sol\n",
      "    - tests/handcrafted-raw/03_SingleModFold_ree3.sol\n",
      "    - tests/handcrafted-raw/03_SingleModSem_ree1.sol\n",
      "    - tests/handcrafted-raw/03_SingleMod_ree1.sol\n",
      "    - tests/handcrafted-raw/03_SingleMod_ree2.sol\n",
      "    - tests/handcrafted-raw/03_SingleMod_ree3.sol\n",
      "    - tests/handcrafted-raw/04_CrossModFold_ree1.sol\n",
      "    - tests/handcrafted-raw/04_CrossModFold_ree2.sol\n",
      "    - tests/handcrafted-raw/04_CrossModFold_ree3.sol\n",
      "    - tests/handcrafted-raw/04_CrossMod_ree1.sol\n",
      "    - tests/handcrafted-raw/04_CrossMod_ree2.sol\n",
      "    - tests/handcrafted-raw/04_CrossMod_ree3.sol\n",
      "    - tests/handcrafted-raw/04_CrossMod_ree4.sol\n",
      "    - tests/handcrafted-raw/04_CrossMod_ree5.sol\n",
      "    - tests/handcrafted-raw/07_MixedTransferEmit_ree1.sol\n",
      "    - tests/handcrafted-raw/07_MixedTransfer_ree1.sol\n",
      "    - tests/handcrafted-raw/08_MixedSendFoldEmit_ree1.sol\n",
      "    - tests/handcrafted-raw/08_MixedSendFold_ree1.sol\n",
      "    - tests/handcrafted-raw/08_MixedSend_ree1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDMod_ree1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDMod_ree2.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDMod_ree3.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DD_ree1.sol\n",
      "    - tests/handcrafted-raw/11_ERC20StakingPullMod_ree1.sol\n",
      "    - tests/handcrafted-raw/11_ERC20StakingPullMod_ree2.sol\n",
      "    - tests/handcrafted-raw/11_ERC20StakingPull_ree1.sol\n",
      "    - tests/handcrafted-raw/11_ERC20Staking_ree1.sol\n",
      "    - tests/handcrafted-raw/11_ERC20Staking_ree2.sol\n",
      "    - tests/handcrafted-raw/11_ERC20Staking_ree3.sol\n",
      "    - tests/handcrafted-raw/13_OnlyOwner_ree1.sol\n",
      "    - tests/handcrafted-raw/14_SidefxInline_ree1.sol\n",
      "    - tests/handcrafted-raw/15_LoopCrossMod_ree1.sol\n",
      "    - tests/handcrafted-raw/15_LoopCrossMod_ree2.sol\n",
      "    - tests/handcrafted-raw/15_LoopCrossMod_ree3.sol\n",
      "    - tests/handcrafted-raw/15_LoopCrossMutex_ree1.sol\n",
      "    - tests/handcrafted-raw/15_Loop_ree1.sol\n",
      "    - tests/handcrafted-raw/16_DelegateCall_ree1.sol\n",
      "    - tests/handcrafted-raw/16_DelegateCall_ree2.sol\n",
      "    - tests/handcrafted-raw/16_DelegateCall_ree3.sol\n",
      "    - tests/handcrafted-raw/19_HumanFold_ree1.sol\n",
      "    - tests/handcrafted-raw/19_HumanFold_ree2.sol\n",
      "    - tests/handcrafted-raw/19_Human_ree1.sol\n",
      "    - tests/handcrafted-raw/19_Human_ree2.sol\n",
      "    - tests/handcrafted-raw/19_Human_ree3.sol\n",
      "    - tests/handcrafted-raw/19_Human_ree4.sol\n",
      "  True Negatives (predicted safe, actually safe):\n",
      "    - tests/handcrafted-raw/00_BasicConst_safe1.sol\n",
      "    - tests/handcrafted-raw/00_BasicError_safe1.sol\n",
      "    - tests/handcrafted-raw/00_BasicNoCall_safe1.sol\n",
      "    - tests/handcrafted-raw/00_BasicStaticcall_safe1.sol\n",
      "    - tests/handcrafted-raw/05_SingleSendEmitUnchecked_safe1.sol\n",
      "    - tests/handcrafted-raw/05_SingleSendEmit_safe1.sol\n",
      "    - tests/handcrafted-raw/05_SingleSendUnchecked_safe1.sol\n",
      "    - tests/handcrafted-raw/05_SingleSend_safe1.sol\n",
      "    - tests/handcrafted-raw/05_SingleSend_safe2.sol\n",
      "    - tests/handcrafted-raw/05_SingleSend_safe3.sol\n",
      "    - tests/handcrafted-raw/06_SingleTransferUnchecked_safe1.sol\n",
      "    - tests/handcrafted-raw/06_SingleTransferUnchecked_safe2.sol\n",
      "    - tests/handcrafted-raw/06_SingleTransfer_safe1.sol\n",
      "    - tests/handcrafted-raw/06_SingleTransfer_safe2.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDSubMod_safe1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20DDSub_safe1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20OnlyOnce_safe1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20OnlyOnce_safe2.sol\n",
      "    - tests/handcrafted-raw/09_ERC20_safe1.sol\n",
      "    - tests/handcrafted-raw/09_ERC20_safe2.sol\n",
      "    - tests/handcrafted-raw/11_ERC20Staking_safe1.sol\n",
      "    - tests/handcrafted-raw/11_ERC20Staking_safe2.sol\n",
      "    - tests/handcrafted-raw/12_ProxyStaticcall_safe1.sol\n",
      "    - tests/handcrafted-raw/17_Rari_safe1.sol\n",
      "    - tests/handcrafted-raw/17_Rari_safe2.sol\n",
      "    - tests/handcrafted-raw/18_RariStaticcall_safe1.sol\n",
      "Dictionary: {'tests/handcrafted-raw/00_BasicCall_safe1.sol': 1, 'tests/handcrafted-raw/00_BasicEmit_safe1.sol': 1, 'tests/handcrafted-raw/00_BasicFold_safe1.sol': 1, 'tests/handcrafted-raw/00_BasicFold_safe2.sol': 1, 'tests/handcrafted-raw/00_BasicNoChecks_safe1.sol': 1, 'tests/handcrafted-raw/00_BasicUnchecked_safe1.sol': 1, 'tests/handcrafted-raw/01_SingleMutexFoldSem_safe1.sol': 1, 'tests/handcrafted-raw/01_SingleMutex_safe1.sol': 1, 'tests/handcrafted-raw/01_SingleMutex_safe2.sol': 1, 'tests/handcrafted-raw/02_CrossMutexSem_safe1.sol': 1, 'tests/handcrafted-raw/02_CrossMutexUnchecked_safe1.sol': 1, 'tests/handcrafted-raw/02_CrossMutex_safe1.sol': 1, 'tests/handcrafted-raw/02_CrossMutex_safe2.sol': 1, 'tests/handcrafted-raw/03_SingleModFoldSem_safe1.sol': 1, 'tests/handcrafted-raw/03_SingleModSem_safe1.sol': 1, 'tests/handcrafted-raw/03_SingleMod_safe2.sol': 1, 'tests/handcrafted-raw/04_CrossModFoldSem_safe1.sol': 1, 'tests/handcrafted-raw/04_CrossModFold_safe1.sol': 1, 'tests/handcrafted-raw/04_CrossMod_safe1.sol': 1, 'tests/handcrafted-raw/04_CrossMod_safe2.sol': 1, 'tests/handcrafted-raw/07_MixedTransferEmit_safe1.sol': 1, 'tests/handcrafted-raw/07_MixedTransfer_safe1.sol': 1, 'tests/handcrafted-raw/08_MixedSendFoldEmit_safe1.sol': 1, 'tests/handcrafted-raw/08_MixedSendFold_safe1.sol': 1, 'tests/handcrafted-raw/08_MixedSend_safe1.sol': 1, 'tests/handcrafted-raw/09_ERC20DDMod_safe1.sol': 1, 'tests/handcrafted-raw/09_ERC20DD_safe1.sol': 1, 'tests/handcrafted-raw/09_ERC20_safe3.sol': 1, 'tests/handcrafted-raw/10_OnlyOnce_safe1.sol': 1, 'tests/handcrafted-raw/10_OnlyOnce_safe2.sol': 1, 'tests/handcrafted-raw/11_ERC20StakingPullMod_safe1.sol': 1, 'tests/handcrafted-raw/11_ERC20StakingPull_safe1.sol': 1, 'tests/handcrafted-raw/11_ERC20StakingPull_safe2.sol': 1, 'tests/handcrafted-raw/11_ERC20Staking_safe3.sol': 1, 'tests/handcrafted-raw/12_Proxy_safe1.sol': 1, 'tests/handcrafted-raw/12_Proxy_safe2.sol': 1, 'tests/handcrafted-raw/13_OnlyOwner_safe1.sol': 1, 'tests/handcrafted-raw/14_SidefxInline_safe1.sol': 1, 'tests/handcrafted-raw/15_LoopCrossMod_safe1.sol': 1, 'tests/handcrafted-raw/15_LoopCrossMutex_safe1.sol': 1, 'tests/handcrafted-raw/15_LoopCrossMutex_safe2.sol': 1, 'tests/handcrafted-raw/15_Loop_safe1.sol': 1, 'tests/handcrafted-raw/16_DelegateCall_safe1.sol': 1, 'tests/handcrafted-raw/19_HumanFold_safe1.sol': 1, 'tests/handcrafted-raw/19_Human_safe1.sol': 1, 'tests/handcrafted-raw/19_Human_safe2.sol': 1, 'tests/handcrafted-raw/19_Human_safe3.sol': 1, 'tests/handcrafted-raw/00_BasicError_ree1.sol': 1, 'tests/handcrafted-raw/09_ERC20DDSubMod_ree1.sol': 1, 'tests/handcrafted-raw/09_ERC20DDSubMod_ree2.sol': 1, 'tests/handcrafted-raw/09_ERC20DDSubMod_ree3.sol': 1, 'tests/handcrafted-raw/09_ERC20DDSub_ree1.sol': 1, 'tests/handcrafted-raw/09_ERC20OnlyOnce_ree1.sol': 1, 'tests/handcrafted-raw/09_ERC20Staticcall_ree1.sol': 1, 'tests/handcrafted-raw/09_ERC20_ree1.sol': 1, 'tests/handcrafted-raw/17_Rari_ree1.sol': 1, 'tests/handcrafted-raw/17_Rari_ree2.sol': 1, 'tests/handcrafted-raw/18_RariStaticcall_ree1.sol': 1, 'tests/handcrafted-raw/19_HumanFold_ree3.sol': 1}\n",
      "\n",
      "---------Misclassified by all tools-------\n",
      "\n",
      "tests/handcrafted-raw/00_BasicCall_safe1.sol 1\n",
      "tests/handcrafted-raw/00_BasicEmit_safe1.sol 1\n",
      "tests/handcrafted-raw/00_BasicFold_safe1.sol 1\n",
      "tests/handcrafted-raw/00_BasicFold_safe2.sol 1\n",
      "tests/handcrafted-raw/00_BasicNoChecks_safe1.sol 1\n",
      "tests/handcrafted-raw/00_BasicUnchecked_safe1.sol 1\n",
      "tests/handcrafted-raw/01_SingleMutexFoldSem_safe1.sol 1\n",
      "tests/handcrafted-raw/01_SingleMutex_safe1.sol 1\n",
      "tests/handcrafted-raw/01_SingleMutex_safe2.sol 1\n",
      "tests/handcrafted-raw/02_CrossMutexSem_safe1.sol 1\n",
      "tests/handcrafted-raw/02_CrossMutexUnchecked_safe1.sol 1\n",
      "tests/handcrafted-raw/02_CrossMutex_safe1.sol 1\n",
      "tests/handcrafted-raw/02_CrossMutex_safe2.sol 1\n",
      "tests/handcrafted-raw/03_SingleModFoldSem_safe1.sol 1\n",
      "tests/handcrafted-raw/03_SingleModSem_safe1.sol 1\n",
      "tests/handcrafted-raw/03_SingleMod_safe2.sol 1\n",
      "tests/handcrafted-raw/04_CrossModFoldSem_safe1.sol 1\n",
      "tests/handcrafted-raw/04_CrossModFold_safe1.sol 1\n",
      "tests/handcrafted-raw/04_CrossMod_safe1.sol 1\n",
      "tests/handcrafted-raw/04_CrossMod_safe2.sol 1\n",
      "tests/handcrafted-raw/07_MixedTransferEmit_safe1.sol 1\n",
      "tests/handcrafted-raw/07_MixedTransfer_safe1.sol 1\n",
      "tests/handcrafted-raw/08_MixedSendFoldEmit_safe1.sol 1\n",
      "tests/handcrafted-raw/08_MixedSendFold_safe1.sol 1\n",
      "tests/handcrafted-raw/08_MixedSend_safe1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20DDMod_safe1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20DD_safe1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20_safe3.sol 1\n",
      "tests/handcrafted-raw/10_OnlyOnce_safe1.sol 1\n",
      "tests/handcrafted-raw/10_OnlyOnce_safe2.sol 1\n",
      "tests/handcrafted-raw/11_ERC20StakingPullMod_safe1.sol 1\n",
      "tests/handcrafted-raw/11_ERC20StakingPull_safe1.sol 1\n",
      "tests/handcrafted-raw/11_ERC20StakingPull_safe2.sol 1\n",
      "tests/handcrafted-raw/11_ERC20Staking_safe3.sol 1\n",
      "tests/handcrafted-raw/12_Proxy_safe1.sol 1\n",
      "tests/handcrafted-raw/12_Proxy_safe2.sol 1\n",
      "tests/handcrafted-raw/13_OnlyOwner_safe1.sol 1\n",
      "tests/handcrafted-raw/14_SidefxInline_safe1.sol 1\n",
      "tests/handcrafted-raw/15_LoopCrossMod_safe1.sol 1\n",
      "tests/handcrafted-raw/15_LoopCrossMutex_safe1.sol 1\n",
      "tests/handcrafted-raw/15_LoopCrossMutex_safe2.sol 1\n",
      "tests/handcrafted-raw/15_Loop_safe1.sol 1\n",
      "tests/handcrafted-raw/16_DelegateCall_safe1.sol 1\n",
      "tests/handcrafted-raw/19_HumanFold_safe1.sol 1\n",
      "tests/handcrafted-raw/19_Human_safe1.sol 1\n",
      "tests/handcrafted-raw/19_Human_safe2.sol 1\n",
      "tests/handcrafted-raw/19_Human_safe3.sol 1\n",
      "tests/handcrafted-raw/00_BasicError_ree1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20DDSubMod_ree1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20DDSubMod_ree2.sol 1\n",
      "tests/handcrafted-raw/09_ERC20DDSubMod_ree3.sol 1\n",
      "tests/handcrafted-raw/09_ERC20DDSub_ree1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20OnlyOnce_ree1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20Staticcall_ree1.sol 1\n",
      "tests/handcrafted-raw/09_ERC20_ree1.sol 1\n",
      "tests/handcrafted-raw/17_Rari_ree1.sol 1\n",
      "tests/handcrafted-raw/17_Rari_ree2.sol 1\n",
      "tests/handcrafted-raw/18_RariStaticcall_ree1.sol 1\n",
      "tests/handcrafted-raw/19_HumanFold_ree3.sol 1\n",
      "\n",
      "\n",
      "Results for toolid: mythril-0.24.7\n",
      "  True Positives (TP):  65\n",
      "  False Positives (FP): 47\n",
      "  True Negatives (TN):  26\n",
      "  False Negatives (FN): 12\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.6067\n",
      "  Precision:            0.5804\n",
      "  Recall (Sensitivity): 0.8442\n",
      "  F1-Score:             0.6878\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "def analyze_csv_data_per_tool(df_input):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "\n",
    "    def determine_ground_truth(filename_val):\n",
    "        if isinstance(filename_val, str):\n",
    "            filename_lower = filename_val.lower()\n",
    "            if \"ree\" in filename_lower:\n",
    "                return 1\n",
    "            if \"safe\" in filename_lower:\n",
    "                return 0\n",
    "        return pd.NA\n",
    "\n",
    "    df['actual_label'] = df['filename'].apply(determine_ground_truth)\n",
    "\n",
    "    original_row_count_before_gt_filter = len(df)\n",
    "    df = df.dropna(subset=['actual_label'])\n",
    "    print(\n",
    "        f\"Filtered out {original_row_count_before_gt_filter - len(df)} rows with ambiguous filenames (not containing 'ree' or 'safe').\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Warning: DataFrame is empty after filtering for 'ree'/'safe' filenames. No data to process.\")\n",
    "        return {}\n",
    "    df['actual_label'] = df['actual_label'].astype(int)\n",
    "\n",
    "    required_columns_for_core_logic = ['filename', 'findings', 'toolid', 'actual_label']\n",
    "    for col in required_columns_for_core_logic:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Critical Error: Column '{col}' is missing after initial processing. Cannot proceed.\")\n",
    "            return {}\n",
    "\n",
    "    results_per_tool = {}\n",
    "    if 'toolid' not in df.columns:\n",
    "        print(\"Critical Error: 'toolid' column is missing. Cannot group results.\")\n",
    "        return {}\n",
    "\n",
    "    unique_toolids = df['toolid'].unique()\n",
    "\n",
    "    d  = {}\n",
    "\n",
    "    for tool_id in unique_toolids:\n",
    "        tool_df_initial = df[df['toolid'] == tool_id].copy()\n",
    "\n",
    "        if tool_df_initial.empty:\n",
    "            continue\n",
    "\n",
    "        tool_df_deduplicated = pd.DataFrame()\n",
    "        if 'start' in tool_df_initial.columns:\n",
    "            tool_df_initial['start_numeric'] = pd.to_numeric(tool_df_initial['start'], errors='coerce')\n",
    "            valid_start_times_df = tool_df_initial.dropna(subset=['start_numeric'])\n",
    "\n",
    "            if not valid_start_times_df.empty:\n",
    "                tool_df_sorted = valid_start_times_df.sort_values(\n",
    "                    by=['filename', 'start_numeric'], ascending=[True, False]\n",
    "                )\n",
    "                tool_df_deduplicated = tool_df_sorted.drop_duplicates(subset=['filename'], keep='first')\n",
    "                print(\n",
    "                    f\"For toolid '{tool_id}', processed {len(tool_df_initial)} rows initially, kept {len(tool_df_deduplicated)} after deduplicating by filename (latest run with valid start time).\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: For toolid '{tool_id}', no valid numeric 'start' times. Using all {len(tool_df_initial)} rows, which might include duplicates.\")\n",
    "                tool_df_deduplicated = tool_df_initial\n",
    "        else:\n",
    "            print(\n",
    "                f\"Warning: 'start' column not found for toolid '{tool_id}'. Using all {len(tool_df_initial)} rows, which might include duplicates.\")\n",
    "            tool_df_deduplicated = tool_df_initial\n",
    "\n",
    "        if tool_df_deduplicated.empty:\n",
    "            print(f\"Warning: No data remaining for toolid '{tool_id}' after deduplication. Skipping.\")\n",
    "            results_per_tool[tool_id] = {\n",
    "                \"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0,\n",
    "                \"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0,\n",
    "                \"error\": \"No data after deduplication\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        tool_df = tool_df_deduplicated\n",
    "        y_true = tool_df['actual_label'].tolist()\n",
    "\n",
    "        reentrancy_keywords = [\n",
    "            \"reentrancy\", \"re-entrancy\", \"reentrant\", \"swc_107\", \"swc-107\",\n",
    "            \"state_access_after_external_call\", \"delegatecall\", \"swc_112\",\n",
    "            \"swc-112\", \"re_entrancy_vulnerability\", \"dao\"\n",
    "        ]\n",
    "        tool_df.loc[:, 'predicted_label'] = tool_df['findings'].apply(\n",
    "            lambda x: 1 if isinstance(x, str) and (\"reentrancy_benign\" not in x.lower()) and (\n",
    "                any(keyword in x.lower() for keyword in reentrancy_keywords)) else 0\n",
    "        )\n",
    "        y_pred = tool_df['predicted_label'].tolist()\n",
    "\n",
    "        if not y_true:\n",
    "            print(f\"Warning: No valid labels collected for toolid '{tool_id}'. Skipping metrics.\")\n",
    "            results_per_tool[tool_id] = {\n",
    "                \"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0,\n",
    "                \"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0,\n",
    "                \"error\": \"No valid labels after processing\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        except ValueError as e:\n",
    "            print(\n",
    "                f\"Warning: Could not compute confusion matrix directly for toolid '{tool_id}': {e}. Manually calculating.\")\n",
    "            tp = sum((yt == 1 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "            fp = sum((yt == 0 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "            tn = sum((yt == 0 and yp == 0) for yt, yp in zip(y_true, y_pred))\n",
    "            fn = sum((yt == 1 and yp == 0) for yt, yp in zip(y_true, y_pred))\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0, labels=[0, 1], pos_label=1)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0, labels=[0, 1], pos_label=1)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0, labels=[0, 1], pos_label=1)\n",
    "\n",
    "        results_per_tool[tool_id] = {\n",
    "            \"tp\": int(tp), \"fp\": int(fp), \"tn\": int(tn), \"fn\": int(fn),\n",
    "            \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1\n",
    "        }\n",
    "\n",
    "        # --- NEW: Print misclassified contracts (FP and FN) ---\n",
    "        misclassified = tool_df[tool_df['actual_label'] != tool_df['predicted_label']]\n",
    "        if not misclassified.empty:\n",
    "            print(f\"\\nMisclassified contracts for toolid '{tool_id}':\")\n",
    "            false_positives = misclassified[misclassified['predicted_label'] == 1]\n",
    "            false_negatives = misclassified[misclassified['predicted_label'] == 0]\n",
    "\n",
    "            if not false_positives.empty:\n",
    "                print(\"  False Positives (predicted vulnerable, actually safe):\")\n",
    "                for fp_fname in false_positives['filename']:\n",
    "                    print(f\"    - {fp_fname}\")\n",
    "                    if fp_fname in d:\n",
    "                        d[fp_fname] += 1\n",
    "                    else:\n",
    "                        d[fp_fname] = 1\n",
    "\n",
    "            if not false_negatives.empty:\n",
    "                print(\"  False Negatives (predicted safe, actually vulnerable):\")\n",
    "                for fn_fname in false_negatives['filename']:\n",
    "                    print(f\"    - {fn_fname}\")\n",
    "                    if fn_fname in d:\n",
    "                        d[fn_fname] += 1\n",
    "                    else:\n",
    "                        d[fn_fname] = 1\n",
    "\n",
    "\n",
    "\n",
    "        classified = tool_df[tool_df['actual_label'] == tool_df['predicted_label']]\n",
    "        if not classified.empty:\n",
    "            print(f\"\\nCorrectly classified contracts for toolid '{tool_id}':\")\n",
    "            true_positives = classified[classified['predicted_label'] == 1]\n",
    "            true_negatives = classified[classified['predicted_label'] == 0]\n",
    "\n",
    "            if not true_positives.empty:\n",
    "                print(\"  True Positives (predicted vulnerable, actually vulnerable):\")\n",
    "                for fp_fname in true_positives['filename']:\n",
    "                    print(f\"    - {fp_fname}\")\n",
    "\n",
    "            if not true_negatives.empty:\n",
    "                print(\"  True Negatives (predicted safe, actually safe):\")\n",
    "                for fn_fname in true_negatives['filename']:\n",
    "                    print(f\"    - {fn_fname}\")\n",
    "\n",
    "\n",
    "    print('Dictionary:', d)\n",
    "    print('\\n---------Misclassified by all tools-------\\n')\n",
    "    for k,v in d.items():\n",
    "        if v >= 1:\n",
    "            print(k, v)    \n",
    "    print()\n",
    "\n",
    "    return results_per_tool\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = \"trs.csv\"\n",
    "    df_main = pd.read_csv(csv_file_path)\n",
    "    print(f\"Successfully loaded '{csv_file_path}', shape: {df_main.shape}\")\n",
    "    df_main = df_main[df_main['toolid'].isin([\n",
    "        #'confuzzius'#,\n",
    "        'mythril-0.24.7'\n",
    "        #'slither-0.10.4'\n",
    "        ])]\n",
    "\n",
    "    \n",
    "\n",
    "    if not df_main.empty:\n",
    "        print(\"\\nAnalyzing CSV data for Reentrancy-related findings per tool (using pandas & sklearn):\\n\")\n",
    "        all_results = analyze_csv_data_per_tool(df_main)\n",
    "\n",
    "        if not all_results:\n",
    "            print(\"No results were generated. Please check the input data and logs.\")\n",
    "        else:\n",
    "            for tool_id, metrics in all_results.items():\n",
    "                print(f\"\\nResults for toolid: {tool_id}\")\n",
    "                if \"error\" in metrics:\n",
    "                    print(f\"  Message: {metrics['error']}\")\n",
    "                elif all(k in metrics for k in [\"tp\", \"fp\", \"tn\", \"fn\"]):\n",
    "                    print(f\"  True Positives (TP):  {metrics['tp']}\")\n",
    "                    print(f\"  False Positives (FP): {metrics['fp']}\")\n",
    "                    print(f\"  True Negatives (TN):  {metrics['tn']}\")\n",
    "                    print(f\"  False Negatives (FN): {metrics['fn']}\")\n",
    "                    print(\"  ------------------------------------\")\n",
    "                    print(f\"  Accuracy:             {metrics['accuracy']:.4f}\")\n",
    "                    print(f\"  Precision:            {metrics['precision']:.4f}\")\n",
    "                    print(f\"  Recall (Sensitivity): {metrics['recall']:.4f}\")\n",
    "                    print(f\"  F1-Score:             {metrics['f1_score']:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  Metrics data incomplete: {metrics}\")\n",
    "                print(\"-\" * 40)\n",
    "    else:\n",
    "        print(\"Could not proceed with analysis as DataFrame is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
