{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35f0aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reentrancy Metrics per Tool:\n",
      "==============================\n",
      "****************************************************************************************************\n",
      "Results for Solidity version: 0.8\n",
      "****************************************************************************************************\n",
      "Tool: vandal\n",
      "  Accuracy:  52.94\n",
      "  Precision: 50.00\n",
      "  Recall:    89.06\n",
      "  F1 Score:  64.04\n",
      "  Errors: 13.97\n",
      "------------------------------\n",
      "****************************************************************************************************\n",
      "Results for Solidity version: 0.5\n",
      "****************************************************************************************************\n",
      "Tool: vandal\n",
      "  Accuracy:  53.03\n",
      "  Precision: 49.56\n",
      "  Recall:    91.80\n",
      "  F1 Score:  64.37\n",
      "  Errors: 11.36\n",
      "------------------------------\n",
      "****************************************************************************************************\n",
      "Results for Solidity version: 0.4\n",
      "****************************************************************************************************\n",
      "Tool: vandal\n",
      "  Accuracy:  51.56\n",
      "  Precision: 48.65\n",
      "  Recall:    91.53\n",
      "  F1 Score:  63.53\n",
      "  Errors: 13.28\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Read data from the CSV file and select only the required columns.\n",
    "filename = 'results_all_bins.csv'\n",
    "\n",
    "if 'src' in filename:\n",
    "    out_csv = 'reentrancy_metrics_data_src.csv'\n",
    "    latex_file = 'latex_table_src.csv'\n",
    "    aggregated_file = 'aggregated_results_src.csv'\n",
    "else:\n",
    "    out_csv = 'reentrancy_metrics_data_bins.csv'\n",
    "    latex_file = 'latex_table_bins.csv'\n",
    "    aggregated_file = 'aggregated_results_bins.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df = df[['filename', 'basename', 'exit_code', 'toolid', 'findings']]\n",
    "\n",
    "df['exit_code'] = df['exit_code'].fillna(-1).astype(int)\n",
    "#print(df.shape)\n",
    "df = df[~((df['toolid'] == 'ethor-2023') & (df['findings'] == '{}'))]\n",
    "df = df[df['basename'].str.contains('_safe|_ree', na=False)]\n",
    "\n",
    "#print(df.shape)\n",
    "# A dictionary mapping each tool to the string(s) it produces for a reentrancy finding.\n",
    "# You can easily update this dictionary as needed. For tools with multiple labels,\n",
    "# use a comma-separated string, e.g., 'tool_name': 'label1,label2'.\n",
    "reentrancy_labels = {\n",
    "    'ccc': 'Reentrancy_Vulnerability',\n",
    "    'confuzzius': 'Reentrancy',\n",
    "    'conkas': 'Reentrancy', #.sol 0.5\n",
    "    #'manticore-0.3.7': 'Reentrancy', # placeholder\n",
    "    'mythril-0.24.7': 'State_access_after_external_call_SWC_107',\n",
    "    'oyente+-2acaf2e': 'Re_Entrancy_Vulnerability',\n",
    "    'securify': 'DAO', \n",
    "    'securify2': 'Reentrancy', # does not work\n",
    "    'sfuzz': 'Reentrancy', \n",
    "    'slither-0.11.3': 'reentrancy_eth,reentrancy_no_eth',\n",
    "    #'smartcheck': 'Reentrancy', # never finds any occurrence of reentrancy\n",
    "    'solhint-6.0.0': 'reentrancy',\n",
    "    #'ethainter': 'Reentrancy', # does not work\n",
    "    'ethor-2023': 'insecure',\n",
    "    'oyente+-060ca34':'Re_Entrancy_Vulnerability',\n",
    "    'vandal': 'ReentrantCall',\n",
    "    'gpt-oss': 'reentrant',\n",
    "    'gpt-5-mini': 'reentrant',\n",
    "    'gpt-5': 'reentrant',\n",
    "    'gpt-5-nano': 'reentrant'\n",
    "    }\n",
    "\n",
    "# 1. Determine the \"true\" reentrancy label for each file based on its filename.\n",
    "# 'ree' followed by an optional number indicates a true reentrancy vulnerability.\n",
    "# df['true_reentrancy'] = df['filename'].str.contains(r'ree\\d*\\.sol', case=False)\n",
    "df['true_reentrancy'] = df['basename'].str.contains(r'_ree', case=False)\n",
    "\n",
    "# 2. Determine the \"predicted\" reentrancy label based on the 'findings' column.\n",
    "# This function will check if any of the tool-specific reentrancy labels are present in the findings.\n",
    "def get_prediction(row):\n",
    "    tool_id = row['toolid']\n",
    "    findings = str(row['findings']) # Convert to string to handle potential NaN values\n",
    "\n",
    "    # Check if the tool is in our labels dictionary.\n",
    "    if tool_id in reentrancy_labels:\n",
    "        # Split the tool's finding string into a list of individual labels.\n",
    "        tool_findings = [f.strip() for f in reentrancy_labels[tool_id].split(',')]\n",
    "        \n",
    "        # Check if any of the tool's labels are present in the findings from the data.\n",
    "        for label in tool_findings:\n",
    "            if label in findings:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df['predicted_reentrancy'] = df.apply(get_prediction, axis=1)\n",
    "#print(df['exit_code']==1)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a new CSV file.\n",
    "df.to_csv(out_csv, index=False)\n",
    "\n",
    "# 3. Calculate metrics for each unique tool and print only the results.\n",
    "# Analyze only the tools present in the reentrancy_labels dictionary.\n",
    "tools_to_analyze = reentrancy_labels.keys()\n",
    "\n",
    "print(\"Reentrancy Metrics per Tool:\")\n",
    "print(\"=\" * 30)\n",
    "versions = ['0_8', '0_5', '0_4']\n",
    "\n",
    "\n",
    "for version in versions:\n",
    "   \n",
    "    version_df = df[df['filename'].str.contains(version)]\n",
    "    print('*' * 100)\n",
    "    print('Results for Solidity version:', version.replace('_', '.'))\n",
    "    print('*' * 100)\n",
    "    for tool in tools_to_analyze:\n",
    "\n",
    "        # Filter the DataFrame for the current tool.\n",
    "        tool_df = version_df[version_df['toolid'] == tool]\n",
    "        n_results = tool_df.shape[0]\n",
    "\n",
    "        ERRORS = (tool_df['exit_code'] != 0).sum()\n",
    "\n",
    "        ERRORS2  = tool_df[(tool_df['exit_code'] != 0) & (tool_df['findings'] == '{}')].shape[0]/n_results if n_results >0 else 0\n",
    "        # Exclude rows where exit_code is not\n",
    "\n",
    "        \n",
    "\n",
    "        tool_df = tool_df[(tool_df['exit_code'] == '0') | ((tool_df['exit_code'] != 0) & tool_df['findings']!= '{}')]\n",
    "\n",
    "        #print( tool_df['findings'], tool_df['findings']!= '{}')\n",
    "        #tool_df = tool_df[tool_df['exit_code'] == '0']\n",
    "        # if tool == 'vandal':\n",
    "        #     print(tool_df, tool_df.shape)\n",
    "\n",
    "        # Calculate True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
    "        TP = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == True)])\n",
    "        FP = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == True)])\n",
    "        TN = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == False)])\n",
    "        FN = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == False)])\n",
    "        # print(TP, FP, TN, FN)\n",
    "        \n",
    "        # Calculate Accuracy, Precision, and Recall.\n",
    "        # Handle cases where the denominator is zero to avoid errors.\n",
    "        accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "        \n",
    "        # Precision: Out of all positive predictions, how many were correct?\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        \n",
    "        # Recall: Out of all actual positives, how many were correctly predicted?\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "        # Calculate the F1 Score\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_score = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n",
    "        #f1_score = f1_score(tool_df['true_reentrancy'], tool_df['predicted_reentrancy'], zero_division=0, average = 'weighted')\n",
    "        if f1_score > 0:\n",
    "            \n",
    "            print(f\"Tool: {tool}\")\n",
    "            print(f\"  Accuracy:  {accuracy*100:.2f}\")\n",
    "            print(f\"  Precision: {precision*100:.2f}\")\n",
    "            print(f\"  Recall:    {recall*100:.2f}\")\n",
    "            print(f\"  F1 Score:  {f1_score*100:.2f}\")\n",
    "            #print(f\"  Errors: {ERRORS}\")\n",
    "            print(f\"  Errors: {ERRORS2*100:.2f}\")\n",
    "            print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83971f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# # Load your CSV\n",
    "# df = pd.read_csv(out_csv)\n",
    "\n",
    "# # 1. Keep only rows where basename contains '_ree'\n",
    "# df = df[df['basename'].str.contains('_ree', na=False)]\n",
    "\n",
    "# # 2. Extract folder path from filename (everything except the last component)\n",
    "# df['path'] = df['filename'].apply(lambda x: str(Path(x).parent))\n",
    "\n",
    "# # 3. Compute TP, FP, FN, TN flags\n",
    "# df['TP'] = (df['true_reentrancy'] & df['predicted_reentrancy'])\n",
    "# df['FP'] = (~df['true_reentrancy'] & df['predicted_reentrancy'])\n",
    "# df['FN'] = (df['true_reentrancy'] & ~df['predicted_reentrancy'])\n",
    "# df['TN'] = (~df['true_reentrancy'] & ~df['predicted_reentrancy'])\n",
    "\n",
    "# # Aggregate by both path and tool_id, include total count\n",
    "# agg = (\n",
    "#     df.groupby(['path', 'toolid'])\n",
    "#       .agg(\n",
    "#           TP=('TP', 'sum'),\n",
    "#           FP=('FP', 'sum'),\n",
    "#           FN=('FN', 'sum'),\n",
    "#           TN=('TN', 'sum'),\n",
    "#           total_rows=('filename', 'count')\n",
    "#       )\n",
    "#       .reset_index()\n",
    "# )\n",
    "\n",
    "\n",
    "# # 5. Save to CSV\n",
    "# agg.to_csv(aggregated_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "810f5993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0_4\n",
      "1       0_5\n",
      "10      0_4\n",
      "11      0_5\n",
      "12      0_4\n",
      "       ... \n",
      "2758    0_8\n",
      "2759    0_8\n",
      "2760    0_8\n",
      "2765    0_8\n",
      "2770    0_8\n",
      "Name: version, Length: 1288, dtype: object\n",
      "0_4\n",
      "Saved LaTeX table for 0_4 → results_0_4.tex\n",
      "→ Removed common prefix and version: 'handcrafted_tests/src/0_8/0_8'\n",
      "0_5\n",
      "Saved LaTeX table for 0_5 → results_0_5.tex\n",
      "→ Removed common prefix and version: 'handcrafted_tests/src/0_8/0_8'\n",
      "0_8\n",
      "Saved LaTeX table for 0_8 → results_0_8.tex\n",
      "→ Removed common prefix and version: 'handcrafted_tests/src/0_8/0_8'\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ---------- Configuration ----------\n",
    "INPUT_CSV = out_csv  # change to your actual CSV file\n",
    "OUTPUT_PREFIX = \"results_\"   # prefix for generated .tex files\n",
    "\n",
    "\n",
    "# ---------- Load and filter data ----------\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Keep only rows where basename contains '_ree'\n",
    "df = df[df['basename'].str.contains('_ree', na=False)]\n",
    "\n",
    "# Extract folder path (directory of each file)\n",
    "if '_bins' in INPUT_CSV:\n",
    "    # Keep only the parent folder up to the desired level (drop the last subdir)\n",
    "    df['path'] = df['filename'].apply(lambda x: str(Path(x).parent.parent))\n",
    "else:\n",
    "    df['path'] = df['filename'].apply(lambda x: str(Path(x).parent))\n",
    "\n",
    "# Keep forward slashes (safe for LaTeX)\n",
    "df['path'] = df['path'].str.replace('\\\\', '/', regex=False)\n",
    "\n",
    "# Extract version number (e.g., 0_4, 0_5, 0_8) from the path\n",
    "df['version'] = df['path'].str.extract(r'[/\\\\](\\d_\\d)[/\\\\]')\n",
    "print(df['version'])\n",
    "# ---------- Compute results ----------\n",
    "# Correct if tool predicted reentrancy correctly\n",
    "df['correct'] = (df['true_reentrancy'] & df['predicted_reentrancy'])\n",
    "\n",
    "# Group by version, tool, and path\n",
    "agg = (\n",
    "    df.groupby(['version', 'toolid', 'path'])\n",
    "      .agg(correct=('correct', 'sum'), total=('filename', 'count'))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Create string like \"1/3\"\n",
    "agg['score'] = agg['correct'].astype(str) + '/' + agg['total'].astype(str)\n",
    "# Keep only tools that found at least one true positive\n",
    "tools_with_tp = agg.groupby('toolid')['correct'].sum()\n",
    "#print(tools_with_tp)\n",
    "tools_to_keep = tools_with_tp[tools_with_tp > 0].index\n",
    "agg = agg[agg['toolid'].isin(tools_to_keep)]\n",
    "\n",
    "\n",
    "\n",
    "for ver, subdf in agg.groupby('version'):\n",
    "    print(ver)\n",
    "    # Pivot: rows = tools, columns = paths\n",
    "    table = (\n",
    "        subdf.pivot(index='toolid', columns='path', values='score')\n",
    "             .fillna('-')\n",
    "             .sort_index(axis=1)\n",
    "    )\n",
    "\n",
    "    # Convert Index to list of strings\n",
    "    cols = list(table.columns)\n",
    "\n",
    "    # Compute the common prefix of all columns\n",
    "    common_prefix = os.path.commonprefix(cols)\n",
    "\n",
    "    # Remove trailing slash if any\n",
    "    if common_prefix.endswith('/') or common_prefix.endswith('\\\\'):\n",
    "        common_prefix = common_prefix[:-1]\n",
    "\n",
    "    # Remove the common prefix from each column\n",
    "    rotated_cols = [\n",
    "        \"\\\\rotatebox{90}{\" + col[len(common_prefix):].lstrip('/\\\\').replace('_', r'\\_') + \"}\"\n",
    "        for col in cols\n",
    "    ]\n",
    "    table.columns = rotated_cols\n",
    "\n",
    "\n",
    "    # Generate LaTeX\n",
    "    latex = table.to_latex(\n",
    "        escape=False,\n",
    "        index=True,\n",
    "        caption=f\"Reentrancy detection results for Solidity {ver}\",\n",
    "        label=f\"tab:{ver}\",\n",
    "        longtable=False\n",
    "    )\n",
    "\n",
    "    # Save to file\n",
    "\n",
    "    output_file = f\"{OUTPUT_PREFIX}{ver}.tex\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(latex)\n",
    "\n",
    "    print(f\"Saved LaTeX table for {ver} → {output_file}\")\n",
    "    print(f\"→ Removed common prefix and version: '{version_prefix}'\")\n",
    "\n",
    "print(\"✅ Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LaTeX table for 0_4 → results_0_4.tex\n",
      "Saved LaTeX table for 0_5 → results_0_5.tex\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "\n",
    "# # ---------- Configuration ----------\n",
    "# INPUT_CSV = out_csv  # change to your actual CSV file\n",
    "# OUTPUT_PREFIX = \"results_\"   # prefix for generated .tex files\n",
    "\n",
    "\n",
    "# # ---------- Load and filter data ----------\n",
    "# df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# # Keep only rows where basename contains '_ree'\n",
    "# df = df[df['basename'].str.contains('_ree', na=False)]\n",
    "\n",
    "# # Extract folder path (directory of each file)\n",
    "# df['path'] = df['filename'].apply(lambda x: str(Path(x).parent))\n",
    "\n",
    "# # Keep forward slashes (safe for LaTeX)\n",
    "# df['path'] = df['path'].str.replace('\\\\', '/', regex=False)\n",
    "\n",
    "# # Extract version number (e.g., 0_4, 0_5, 0_8) from the path\n",
    "# df['version'] = df['path'].str.extract(r'[/\\\\](\\d_\\d)[/\\\\]')\n",
    "\n",
    "# # ---------- Compute results ----------\n",
    "# # Correct if tool predicted reentrancy correctly\n",
    "# df['correct'] = (df['true_reentrancy'] & df['predicted_reentrancy'])\n",
    "\n",
    "# # Group by version, tool, and path\n",
    "# agg = (\n",
    "#     df.groupby(['version', 'toolid', 'path'])\n",
    "#       .agg(correct=('correct', 'sum'), total=('filename', 'count'))\n",
    "#       .reset_index()\n",
    "# )\n",
    "\n",
    "# # Create string like \"1/3\"\n",
    "# agg['score'] = agg['correct'].astype(str) + '/' + agg['total'].astype(str)\n",
    "# # Keep only tools that found at least one true positive\n",
    "# tools_with_tp = agg.groupby('toolid')['correct'].sum()\n",
    "# tools_to_keep = tools_with_tp[tools_with_tp > 0].index\n",
    "# agg = agg[agg['toolid'].isin(tools_to_keep)]\n",
    "\n",
    "\n",
    "# for ver, subdf in agg.groupby('version'):\n",
    "#     # Pivot: rows = tools, columns = paths\n",
    "#     table = (\n",
    "#         subdf.pivot(index='toolid', columns='path', values='score')\n",
    "#              .fillna('-')\n",
    "#              .sort_index(axis=1)\n",
    "#     )\n",
    "\n",
    "#     # Convert Index to list of strings\n",
    "#     cols = list(table.columns)\n",
    "\n",
    "#     # Compute the common prefix of all columns\n",
    "#     common_prefix = os.path.commonprefix(cols)\n",
    "\n",
    "#     # Remove trailing slash if any\n",
    "#     if common_prefix.endswith('/') or common_prefix.endswith('\\\\'):\n",
    "#         common_prefix = common_prefix[:-1]\n",
    "\n",
    "#     # Remove the common prefix from each column\n",
    "#     rotated_cols = [\n",
    "#         \"\\\\rotatebox{90}{\" + col[len(common_prefix):].lstrip('/\\\\').replace('_', r'\\_') + \"}\"\n",
    "#         for col in cols\n",
    "#     ]\n",
    "#     table.columns = rotated_cols\n",
    "\n",
    "#     # Generate LaTeX table as string\n",
    "#     latex_body = table.to_latex(\n",
    "#         escape=False,\n",
    "#         index=True\n",
    "#     )\n",
    "\n",
    "#     # Wrap with resizebox and add caption/label manually\n",
    "#     latex = (\n",
    "#         \"\\\\begin{table}\\n\"\n",
    "#         f\"\\\\caption{{Reentrancy detection results for Solidity {ver}}}\\n\"\n",
    "#         f\"\\\\label{{tab:{ver}}}\\n\"\n",
    "#         \"\\\\resizebox{\\\\textwidth}{!}{%\\n\"\n",
    "#         f\"{latex_body}\"\n",
    "#         \"}\\n\"\n",
    "#         \"\\\\end{table}\\n\"\n",
    "#     )\n",
    "\n",
    "#     # Save to file\n",
    "#     output_file = f\"{OUTPUT_PREFIX}{ver}.tex\"\n",
    "#     with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(latex)\n",
    "\n",
    "#     print(f\"Saved LaTeX table for {ver} → {output_file}\")\n",
    "\n",
    "# print(\"✅ Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
